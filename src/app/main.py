"""
main.py
-----------------
Main pipeline for driver fatigue detection system

Functions:
- Orchestrate entire pipeline from camera â†’ processing â†’ display
- Integrate landmark detection, rule-based analysis
- Display real-time results with English UI
- Logging and data storage
"""

import cv2
import time
import logging
import threading
from typing import Optional, Dict, Any
import numpy as np

# Import internal modules
from .config import (
    get_fatigue_config, get_alert_color, get_recommendation, get_display_text,
    CAMERA_CONFIG, MEDIAPIPE_CONFIG, DISPLAY_CONFIG, COLORS, MESSAGES
)

# Import processing layers
from ..input_layer.camera_handler import CameraHandler
from ..processing_layer.detect_landmark.landmark import FaceLandmarkDetector
from ..processing_layer.vision_processor.rule_based import RuleBasedFatigueDetector, FatigueDetectionConfig


class FatigueDetectionPipeline:
    """
    Main pipeline for fatigue detection system
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize pipeline"""
        self.setup_logging()
        self.logger = logging.getLogger("FatigueDetectionPipeline")
        
        # Load config
        self.config = config or get_fatigue_config()
        
        # Components
        self.camera = None
        self.landmark_detector = None
        self.fatigue_detector = None
        
        # State
        self.is_running = False
        self.frame_count = 0
        self.start_time = time.time()
        
        # Statistics
        self.stats = {
            "total_frames": 0,
            "faces_detected": 0,
            "alerts_triggered": 0,
            "last_alert_time": None
        }
        
        self.logger.info("ğŸ¯ Initializing fatigue detection system")
    
    def setup_logging(self):
        """Setup logging"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler("log/fatigue_detection.log", encoding='utf-8')
            ]
        )
    
    def initialize_components(self):
        """Initialize components"""
        try:
            # Camera
            self.logger.info("ğŸ“¹ Initializing camera...")
            self.camera = CameraHandler(**CAMERA_CONFIG)
            
            # Landmark detector
            self.logger.info("ğŸ­ Initializing landmark detector...")
            self.landmark_detector = FaceLandmarkDetector(**MEDIAPIPE_CONFIG)
            
            # Fatigue detector
            self.logger.info("ğŸ§  Initializing fatigue detector...")
            config = get_fatigue_config()
            self.fatigue_detector = RuleBasedFatigueDetector(**config)
            
            self.logger.info("âœ… Successfully initialized all components")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Initialization error: {e}")
            return False
    
    def process_frame(self, frame: np.ndarray) -> tuple:
        """
        Xá»­ lÃ½ má»™t frame
        
        Returns:
            tuple: (annotated_frame, fatigue_result)
        """
        if frame is None:
            return None, None
        
        self.frame_count += 1
        self.stats["total_frames"] += 1
        
        # 1. PhÃ¡t hiá»‡n landmarks
        landmarks, annotated = self.landmark_detector.detect(frame, draw=False)
        
        # 2. Náº¿u cÃ³ khuÃ´n máº·t, tiáº¿n hÃ nh phÃ¢n tÃ­ch
        fatigue_result = None
        if landmarks:
            self.stats["faces_detected"] += 1
            
            # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
            features = self.landmark_detector.extract_important_points(landmarks)
            
            if features:
                # Váº½ debug overlay
                annotated = self.landmark_detector.draw_debug_overlay(annotated, features)
                
                # PhÃ¢n tÃ­ch má»‡t má»i
                fatigue_result = self.fatigue_detector.process_frame(features, frame.shape)
                
                # Cáº­p nháº­t thá»‘ng kÃª
                if fatigue_result["alert_level"].value in ["HIGH", "CRITICAL"]:
                    self.stats["alerts_triggered"] += 1
                    self.stats["last_alert_time"] = time.time()
        
        return annotated, fatigue_result
    
    def draw_ui(self, frame: np.ndarray, fatigue_result: Optional[Dict]) -> np.ndarray:
        """
        Váº½ giao diá»‡n ngÆ°á»i dÃ¹ng trÃªn frame
        """
        if frame is None:
            return np.zeros((480, 640, 3), dtype=np.uint8)
        
        # TÃ­nh FPS
        current_time = time.time()
        fps = self.frame_count / (current_time - self.start_time) if current_time > self.start_time else 0
        
        # Background overlay cho thÃ´ng tin
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (400, 200), COLORS["BACKGROUND"], -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        y_offset = 30
        
        # FPS vÃ  frame count
        cv2.putText(frame, f"FPS: {fps:.1f}", 
                   (10, y_offset), DISPLAY_CONFIG["font"], 0.6, COLORS["TEXT_NORMAL"], 1)
        cv2.putText(frame, f"Frame: {self.frame_count}", 
                   (150, y_offset), DISPLAY_CONFIG["font"], 0.6, COLORS["TEXT_NORMAL"], 1)
        y_offset += 25
        
        # ThÃ´ng tin phÃ¡t hiá»‡n má»‡t má»i
        if fatigue_result:
            alert_level = fatigue_result["alert_level"].value
            fatigue_state = fatigue_result["fatigue_state"].value
            confidence = fatigue_result["confidence"]
            
            # MÃ u sáº¯c theo má»©c Ä‘á»™
            color = get_alert_color(alert_level)
            
            # Main status
            cv2.putText(frame, f"Status: {alert_level}", 
                       (10, y_offset), DISPLAY_CONFIG["font"], 0.7, color, 2)
            y_offset += 30
            
            # Äá»™ tin cáº­y
            cv2.putText(frame, f"Do tin cay: {confidence:.2f}", 
                       (10, y_offset), DISPLAY_CONFIG["font"], 0.6, color, 2)
            y_offset += 25
            
            # Chi tiáº¿t cÃ¡c chá»‰ sá»‘
            if fatigue_result["ear"]:
                ear_val = fatigue_result["ear"]["ear_value"]
                ear_state = fatigue_result["eye_state"].value  # Sá»­ dá»¥ng state má»›i
                cv2.putText(frame, f"EAR: {ear_val:.3f} ({ear_state})", 
                           (10, y_offset), DISPLAY_CONFIG["font"], 0.5, COLORS["TEXT_NORMAL"], 1)
                y_offset += 20
            
            if fatigue_result["mar"]:
                mar_val = fatigue_result["mar"]["mar_value"]
                mar_state = fatigue_result["mouth_state"].value  # Sá»­ dá»¥ng state má»›i
                cv2.putText(frame, f"MAR: {mar_val:.3f} ({mar_state})", 
                           (10, y_offset), DISPLAY_CONFIG["font"], 0.5, COLORS["TEXT_NORMAL"], 1)
                y_offset += 20
            
            if fatigue_result["head_pose"]:
                pitch = fatigue_result["head_pose"]["pitch"]
                pose_state = fatigue_result["head_state"].value  # Sá»­ dá»¥ng state má»›i
                cv2.putText(frame, f"Pitch: {pitch:.1f}Â° ({pose_state})", 
                           (10, y_offset), DISPLAY_CONFIG["font"], 0.5, COLORS["TEXT_NORMAL"], 1)
                y_offset += 20
            
            # Khuyáº¿n nghá»‹
            recommendation = get_recommendation(alert_level)
            if alert_level in ["HIGH", "CRITICAL"]:
                # Cáº£nh bÃ¡o nhÃ¡y
                blink = int(time.time() * 3) % 2
                if blink:
                    cv2.rectangle(frame, (0, frame.shape[0]-80), (frame.shape[1], frame.shape[0]), color, -1)
                    cv2.putText(frame, recommendation, 
                               (10, frame.shape[0]-30), DISPLAY_CONFIG["font"], 0.8, (255, 255, 255), 2)
            else:
                cv2.putText(frame, recommendation, 
                           (10, frame.shape[0]-30), DISPLAY_CONFIG["font"], 0.6, color, 1)
        else:
            # KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t
            cv2.putText(frame, get_display_text("no_face"), 
                       (10, y_offset), DISPLAY_CONFIG["font"], 0.7, COLORS["TEXT_WARNING"], 2)
        
        # Thá»‘ng kÃª á»Ÿ gÃ³c pháº£i
        stats_x = frame.shape[1] - 200
        cv2.putText(frame, f"Khuon mat: {self.stats['faces_detected']}/{self.stats['total_frames']}", 
                   (stats_x, 30), DISPLAY_CONFIG["font"], 0.5, COLORS["TEXT_NORMAL"], 1)
        cv2.putText(frame, f"Canh bao: {self.stats['alerts_triggered']}", 
                   (stats_x, 50), DISPLAY_CONFIG["font"], 0.5, COLORS["TEXT_NORMAL"], 1)
        
        return frame
    
    def run(self):
        """Cháº¡y pipeline chÃ­nh"""
        if not self.initialize_components():
            return False
        
        self.logger.info("ğŸš€ Báº¯t Ä‘áº§u pipeline phÃ¡t hiá»‡n má»‡t má»i")
        
        try:
            # Khá»Ÿi Ä‘á»™ng camera
            self.camera.start()
            time.sleep(1.0)  # Chá» camera á»•n Ä‘á»‹nh
            
            self.is_running = True
            self.start_time = time.time()
            
            self.logger.info("âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng - Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t, 'r' Ä‘á»ƒ reset")
            
            while self.is_running:
                # Äá»c frame
                frame = self.camera.read_frame()
                
                if frame is None:
                    time.sleep(0.01)
                    continue
                
                # Xá»­ lÃ½ frame
                annotated, fatigue_result = self.process_frame(frame)
                
                # Váº½ UI
                display_frame = self.draw_ui(annotated, fatigue_result)
                
                # Hiá»ƒn thá»‹
                cv2.imshow(DISPLAY_CONFIG["window_name"], display_frame)
                
                # Xá»­ lÃ½ input
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.logger.info("ğŸ›‘ NgÆ°á»i dÃ¹ng yÃªu cáº§u thoÃ¡t")
                    break
                elif key == ord('r'):
                    self.logger.info("ğŸ”„ Reset session")
                    self.fatigue_detector.reset_session()
                    self.stats["alerts_triggered"] = 0
                elif key == ord('s'):
                    # LÆ°u áº£nh
                    timestamp = int(time.time())
                    filename = f"snapshot_{timestamp}.jpg"
                    cv2.imwrite(filename, display_frame)
                    self.logger.info(f"ğŸ“¸ ÄÃ£ lÆ°u áº£nh: {filename}")
                
                # Log important alerts
                if fatigue_result and fatigue_result["alert_level"].value == "CRITICAL":
                    self.logger.warning("ğŸ†˜ CRITICAL ALERT: Severe fatigue detected!")
                elif fatigue_result and fatigue_result["alert_level"].value == "HIGH":
                    self.logger.warning("ğŸš¨ WARNING: Fatigue signs detected!")
        
        except KeyboardInterrupt:
            self.logger.info("âŒ¨ï¸  Dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng (Ctrl+C)")
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh cháº¡y: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """Dá»n dáº¹p tÃ i nguyÃªn"""
        self.logger.info("ğŸ§¹ Äang dá»n dáº¹p tÃ i nguyÃªn...")
        
        self.is_running = False
        
        # Dá»«ng camera
        if self.camera:
            self.camera.release()
        
        # Dá»«ng landmark detector
        if self.landmark_detector:
            self.landmark_detector.release()
        
        # ÄÃ³ng cá»­a sá»•
        cv2.destroyAllWindows()
        
        # In thá»‘ng kÃª cuá»‘i
        if self.fatigue_detector:
            summary = self.fatigue_detector.get_detection_summary()
            self.logger.info(f"ğŸ“Š Thá»‘ng kÃª phiÃªn lÃ m viá»‡c:")
            self.logger.info(f"   - Tá»•ng frame: {self.stats['total_frames']}")
            self.logger.info(f"   - PhÃ¡t hiá»‡n khuÃ´n máº·t: {self.stats['faces_detected']}")
            self.logger.info(f"   - Cáº£nh bÃ¡o: {self.stats['alerts_triggered']}")
            self.logger.info(f"   - Tráº¡ng thÃ¡i cuá»‘i: {summary.get('latest_state', 'UNKNOWN')}")
        
        self.logger.info("âœ… Dá»n dáº¹p hoÃ n táº¥t")

    def get_current_stats(self) -> Dict[str, Any]:
        """Láº¥y thá»‘ng kÃª hiá»‡n táº¡i"""
        return {
            "uptime": time.time() - self.start_time,
            "fps": self.frame_count / (time.time() - self.start_time) if time.time() > self.start_time else 0,
            **self.stats
        }


def create_pipeline(config: Optional[Dict[str, Any]] = None) -> FatigueDetectionPipeline:
    """Factory function Ä‘á»ƒ táº¡o pipeline"""
    return FatigueDetectionPipeline(config)


if __name__ == "__main__":
    # Test pipeline
    print("ğŸ§ª Test cháº¡y pipeline...")
    pipeline = create_pipeline()
    try:
        pipeline.run()
    except KeyboardInterrupt:
        print("\nâŒ¨ï¸  Test dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
    except Exception as e:
        print(f"âŒ Lá»—i test: {e}")
    finally:
        print("ğŸ Test hoÃ n táº¥t")
    pipeline = create_pipeline()
    pipeline.run()
